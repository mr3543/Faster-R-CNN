{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"faster_rcnn","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wmIVwGH5smIJ","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import os.path as osp\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from pycocotools.coco import COCO\n","import matplotlib.patches as patches\n","import tensorflow.contrib.slim as slim\n","import math\n","import gc\n","import sys"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNoiK6ws8zlP","colab_type":"code","colab":{}},"source":["# Import params module. \n","from google.colab import files\n","src = list(files.upload().values())[0]\n","open('params.py','wb').write(src)\n","import params"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rFvpu32I8z3l","colab_type":"code","colab":{}},"source":["# Import data_utils module. \n","from google.colab import files\n","src = list(files.upload().values())[0]\n","open('data_utils.py','wb').write(src)\n","import data_utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbLsrrtJ8z_p","colab_type":"code","colab":{}},"source":["# Import network_utils module. \n","from google.colab import files\n","src = list(files.upload().values())[0]\n","open('network_utils.py','wb').write(src)\n","import network_utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jd5FMxt5xzH-","colab_type":"code","colab":{}},"source":["# if necessary download image data\n","\n","! mkdir image_data\n","! wget http://images.cocodataset.org/zips/val2017.zip\n","! unzip val2017.zip -d ./image_data\n","! rm val2017.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QL0H_hYm1THV","colab_type":"code","colab":{}},"source":["# download annotations \n","\n","! wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","! unzip annotations_trainval2017.zip -d ./image_data\n","! rm annotations_trainval2017.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"htHJ1DrvJDV8","colab_type":"code","colab":{}},"source":["with tf.Graph().as_default() as g:\n","  \n","  image = tf.placeholder(shape=[1,None,None,3],dtype = tf.float32)\n","  gt_boxes = tf.placeholder(shape=[None,5],dtype = tf.float32)\n","  image_info = tf.placeholder(shape=[3,],dtype = tf.float32)\n","  \n","  # add inception network to graph\n","  with tf.variable_scope('base_model'):\n","    base_model = tf.keras.applications.inception_v3.InceptionV3(include_top = False,\n","                                                             weights = 'imagenet',\n","                                                             input_shape= (None,None,3))\n","  # make feature map\n","  feature_map = base_model(image)\n","  # make anchors \n","  anchor_boxes = network_utils.get_anchor_boxes(image_info,feature_map)\n","  num_anchors = params.num_anchors\n","  num_anchor_locs = tf.shape(feature_map)[1]*tf.shape(feature_map)[2]\n","  \n"," \n","  init = tf.random_normal_initializer(mean=0,stddev=0.01)\n","  with slim.arg_scope([slim.conv2d],activation_fn = tf.nn.relu,\n","                       padding='SAME',weights_initializer=init):\n","    with tf.variable_scope('rpn_network'):\n","      \n","      # construct the rpn network\n","      net = slim.conv2d(feature_map,params.rpn_channels,[3,3])\n","      cls_scores = slim.conv2d(net,num_anchors*2,[1,1],activation_fn=None,\n","                              padding='VALID')\n","      bbox_adjs = slim.conv2d(net,num_anchors*4,[1,1],activation_fn=None,\n","                             padding='VALID')\n","     \n","      # get the anchor labels and sample anchors for training \n","      anchor_labels,anchor_bbox_adjs,_ = tf.py_func(network_utils.get_anchor_labels,\n","                                                    [anchor_boxes,gt_boxes,params.rpn_pos_anchor_thresh,params.rpn_neg_anchor_thresh_lo,params.rpn_neg_anchor_thresh_hi],\n","                                                    [tf.float32,tf.float32,tf.int32])\n","    \n","      anchor_mask = tf.py_func(network_utils.sample_anchors_for_training,[anchor_labels,params.rpn_mini_batch,params.rpn_prop_pos],tf.int32)\n","      num_pos = tf.reduce_sum(tf.cast(tf.equal(anchor_mask,1),tf.int32))\n","      \n","      # reformat the anchor labels for one hot encoding\n","      anchor_labels_ce = tf.py_func(network_utils.make_anchor_ce_labels,[anchor_labels,anchor_mask],[tf.int32])[0]\n","      inds = tf.where(tf.not_equal(anchor_mask,0))\n","      cls_scores_reshape = tf.reshape(cls_scores,(-1,2))\n","      cls_scores_ce = tf.gather_nd(cls_scores_reshape,inds)\n","      num_scores = tf.shape(cls_scores_ce)[0]\n","      \n","      cls_preds = tf.ones(num_scores,dtype=tf.int32)-tf.cast(tf.argmax(cls_scores_ce,axis=1),dtype=tf.int32)\n","      cls_accuracy = tf.reduce_sum(tf.cast(tf.equal(cls_preds,anchor_labels_ce[:,0]),dtype=tf.int32))/num_scores\n","      pos_preds = tf.reduce_sum(cls_preds)\n","      tf.summary.scalar('cls_accuracy',cls_accuracy)\n","      \n","      # compute the cross entropy loss\n","      rpn_cls_ce = tf.nn.softmax_cross_entropy_with_logits(labels=anchor_labels_ce,logits=cls_scores_ce)\n","      rpn_cls_loss = tf.reduce_mean(rpn_cls_ce)\n","      tf.summary.scalar('rpn_cls_loss',rpn_cls_loss)\n","      \n","      # compute the bbox regression loss\n","      inds = tf.where(tf.equal(anchor_mask,1))\n","      bbox_adjs_reshape = tf.reshape(bbox_adjs,(-1,4))\n","      bbox_adjs_reshape_batch = tf.gather_nd(bbox_adjs_reshape,inds)\n","      anchor_bbox_adjs_reshape_batch = tf.gather_nd(anchor_bbox_adjs,inds)\n","      rpn_bbox_loss = tf.losses.huber_loss(anchor_bbox_adjs_reshape_batch,bbox_adjs_reshape_batch)\n","      tf.summary.scalar('rpn_bbox_loss',rpn_bbox_loss)\n","      \n","      # compute the total rpn loss for the mini-batch\n","      rpn_total_loss = tf.cast(rpn_cls_loss,tf.float32) + tf.cast(params.rpn_gamma,tf.float32)*(1/tf.cast(num_anchor_locs,tf.float32))*tf.cast(rpn_bbox_loss,tf.float32)\n","      tf.summary.scalar('rpn_total_loss',rpn_total_loss)\n","      \n","      # compute and apply gradients\n","      rpn_learning_rate = tf.placeholder(tf.float32)\n","      rpn_optimizer = tf.contrib.opt.MomentumWOptimizer(params.rpn_weight_decay,\n","                                                        rpn_learning_rate,\n","                                                        params.rpn_momentum)\n","      \n","      # make sure to only train variables from rpn network - not from base model\n","      rpn_training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'rpn_network')\n","      rpn_grads = rpn_optimizer.compute_gradients(rpn_total_loss,var_list = rpn_training_vars)\n","      rpn_training_op = rpn_optimizer.apply_gradients(rpn_grads)\n","      \n","      init_rpn_training_op = tf.variables_initializer(rpn_training_vars)\n","      init_rpn_momen_op = tf.variables_initializer(rpn_optimizer.variables())\n","      \n","      # add network variables to tensorboard \n","      for var in rpn_training_vars:\n","        tf.summary.histogram(var.name,var)\n","  \n","      rpn_merged_summary = tf.summary.merge_all()\n","    \n","    with tf.variable_scope('fast_rcnn_network'):\n","      #### add network structure for fast-rcnn\n","      training_rcnn = tf.placeholder(tf.int32)\n","      rcnn_learning_rate = tf.placeholder(tf.float32)\n","      \n","      # roi pooling\n","      rois,roi_cls_labels,roi_bbox_gts = network_utils.select_rois(anchor_boxes,gt_boxes,bbox_adjs_reshape,cls_scores_reshape[:,0],cls_preds,training_rcnn)\n","      \n","      roi_pools = network_utils.roi_pooling(rois,feature_map,image_info)\n","     \n","      roi_pools = slim.max_pool2d(roi_pools,[2,2],padding='SAME')\n","      \n","      # fast rcnn network \n","      roi_pools_flat = slim.flatten(roi_pools)\n","      fc0 = slim.fully_connected(roi_pools_flat,4096,weights_initializer=init)\n","      fc1 = slim.fully_connected(fc0,4096)\n","      rcnn_cls_scores = slim.fully_connected(fc1,params.num_classes,activation_fn=None,weights_initializer=init)\n","      rcnn_bbox_adjs = slim.fully_connected(fc1,params.num_classes*4,activation_fn=None,weights_initializer=init)\n","      rcnn_bbox_adjs_reshape = tf.reshape(rcnn_bbox_adjs,(-1,params.num_classes,4))\n","      \n","      # compute fast rcnn training classification loss\n","      rcnn_one_hots = tf.one_hot(roi_cls_labels,params.num_classes)\n","      rcnn_cls_ce = tf.nn.softmax_cross_entropy_with_logits(labels=rcnn_one_hots,logits=rcnn_cls_scores)\n","      rcnn_cls_loss = tf.reduce_mean(rcnn_cls_ce)\n","      \n","      # select the positive rois and the correct class label bbox adjustment\n","      pos_rois = tf.where(tf.not_equal(roi_cls_labels,0))\n","      roi_bbox_gts_batch = tf.gather_nd(roi_bbox_gts,pos_rois)\n","      roi_cls_labels_batch = tf.gather_nd(roi_cls_labels,pos_rois)\n","      rcnn_bbox_adjs_reshape_batch = tf.gather_nd(rcnn_bbox_adjs_reshape,pos_rois)\n","      inds = tf.stack((tf.range(tf.shape(rcnn_bbox_adjs_reshape_batch)[0]),roi_cls_labels_batch),axis=1)\n","      rcnn_bbox_adjs_reshape_batch = tf.gather_nd(rcnn_bbox_adjs_reshape_batch,inds)\n","      \n","      # compute the fast rcnn bbox regression loss\n","      rcnn_bbox_loss = tf.losses.huber_loss(roi_bbox_gts_batch,rcnn_bbox_adjs_reshape_batch)\n","      \n","      # fast rcnn total loss\n","      rcnn_total_loss = rcnn_cls_loss + params.rcnn_gamma*rcnn_bbox_loss\n","      \n","      tf.summary.scalar('rcnn_cls_loss',rcnn_cls_loss)\n","      tf.summary.scalar('rcnn_bbox_loss',rcnn_bbox_loss)\n","      tf.summary.scalar('rcnn_total_loss',rcnn_total_loss)\n","      \n","      # compute and apply gradients\n","      rcnn_learning_rate = tf.placeholder(tf.float32)\n","      rcnn_optimizer = tf.contrib.opt.MomentumWOptimizer(params.rcnn_weight_decay,\n","                                                         rcnn_learning_rate,\n","                                                         params.rcnn_momentum)\n","      \n","      # get fast rcnn training vars\n","      rcnn_training_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'fast_rcnn_network')\n","      rcnn_grads = rcnn_optimizer.compute_gradients(rcnn_total_loss,var_list=rcnn_training_vars)\n","      rcnn_training_op = rcnn_optimizer.apply_gradients(rcnn_grads)\n","      \n","      # minimize loss\n","      init_rcnn_training_op = tf.variables_initializer(rcnn_training_vars)\n","      init_rcnn_momen_op = tf.variables_initializer(rcnn_optimizer.variables())\n","      \n","      rcnn_merged_summary = tf.summary.merge_all()\n","    \n","  with tf.keras.backend.get_session() as sess:\n","    # train rpn network\n","    writer = tf.summary.FileWriter('./graphs')\n","    writer.add_graph(sess.graph)\n","    sess.run(init_rpn_training_op)\n","    sess.run(init_rpn_momen_op)\n","    im_permutation = data_utils.get_image_permutation(params.np_random_seed,'val2017')\n","    print('num images: ',len(im_permutation))\n","    i = 0 \n","    while i < 25:\n","      training_images,gt_training_boxes,im_infos = data_utils.get_training_data(i,im_permutation,params.image_batch_size,'val2017')\n","      j=0\n","      while j < len(training_images):\n","        training_image = training_images[j]\n","        gt_training_box = gt_training_boxes[j]\n","        im_info = im_infos[j]\n","        feed_dict = {image:training_image,gt_boxes:gt_training_box,rpn_learning_rate:params.lr1,\n","                     image_info:[im_info['height'],im_info['width'],im_info['id']]}\n","        sess.run(rpn_training_op,feed_dict = feed_dict)\n","        if j % 10 == 0:\n","          s,ca,pp,rcl,rbl,rtl,cls_ce,cls_p,al_ce,num_p = sess.run([rpn_merged_summary,cls_accuracy,pos_preds,rpn_cls_loss,\n","                        rpn_bbox_loss,rpn_total_loss,cls_scores_ce,cls_preds,anchor_labels_ce,num_pos],feed_dict = feed_dict)\n","          writer.add_summary(s,i*params.image_batch_size + j)\n","          print('--------------------')\n","          print('num positive samples: ',num_p)\n","          print('class accuracy: ',ca)\n","          print('positive preds: ',pp)\n","          print('rpn class loss: ',rcl)\n","          print('rpn bbox loss: ',rbl)\n","          print('rpn total loss: ',rtl)\n","          print('-------------------')\n","        j=j+1\n","      i=i+1\n","      print('done {} iterations'.format(i*params.image_batch_size))\n","    \n","    # train rcnn network\n","    i=0\n","    im_permutation = data_utils.get_image_permutation(params.np_random_seed+1,'val2017')\n","    sess.run(init_rcnn_training_op)\n","    sess.run(init_rcnn_momen_op)\n","    while i < params.num_image_batches:\n","      training_images,gt_training_boxes,im_infos = data_utils.get_training_data(i,im_permutation,params.image_batch_size,'val2017')\n","      j=0\n","      while j < len(training_images):\n","        training_image = training_images[j]\n","        gt_training_box = gt_training_boxes[j]\n","        im_info = im_infos[j]\n","        feed_dict = {image:training_image,gt_boxes:gt_training_box,\n","                     image_info:[im_info['height'],im_info['width'],im_info['id']],\n","                     rcnn_learning_rate:params.rcnn_learning_rate,training_rcnn:1}\n","        sess.run(rcnn_training_op,feed_dict=feed_dict)\n","        if j % 10 == 0:\n","          s = sess.run(rcnn_merged_summary,feed_dict=feed_dict)\n","          writer.add_summary(s,i*params.image_batch_size + j)\n","        j=j+1\n","      i=i+1\n","      print('done {} iterations of rcnn training'.format(i*params.image_batch_size))\n","          "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"POz2OWN6JDbm","colab_type":"code","colab":{}},"source":["# Run Tensorboard\n","LOG_DIR = './graphs'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGpug5wqJDeQ","colab_type":"code","colab":{}},"source":["# Download and unzip ngrok\n","! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","! unzip ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gu9j4rtCJDg7","colab_type":"code","colab":{}},"source":["# Launch the ngrok background process\n","get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMmUgQsOJDjV","colab_type":"code","colab":{}},"source":["# Get the public URL\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FujlX7gqJDqz","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbl39n_iJDtM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"at47iMv4JDvs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pxlCgkJqJDxy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gl41qb7Vsbkj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}